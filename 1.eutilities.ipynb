{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Massive PubMed record summary querier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import datetime\n",
    "import logging\n",
    "import lzma\n",
    "import os\n",
    "import time\n",
    "\n",
    "import lxml.etree\n",
    "import pandas\n",
    "import requests\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Publication dates to query\n",
    "start_year = 1960\n",
    "end_year = 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_ids = os.path.join('download', f'esearch_journal-articles_{start_year}-{end_year}.tsv.xz')\n",
    "path_summaries = os.path.join('download', f'esummary_journal-articles_{start_year}-{end_year}.xml.xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `esearch`: retrieve all PubMed article IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def esearch_query(payload, retmax = 10000, sleep=0.34):\n",
    "    \"\"\"\n",
    "    Return identifiers using the ESearch E-utility.\n",
    "    \"\"\"\n",
    "    url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi'\n",
    "    payload['rettype'] = 'xml'\n",
    "    payload['retmax'] = retmax\n",
    "    payload['retstart'] = 0\n",
    "    ids = list()\n",
    "    count = 1\n",
    "    progress_bar = None\n",
    "    while payload['retstart'] < count:\n",
    "        response = requests.get(url, params=payload)\n",
    "        tree = lxml.etree.fromstring(response.content)\n",
    "        count = int(tree.findtext('Count'))\n",
    "        if not progress_bar:\n",
    "            progress_bar = tqdm.tqdm_notebook(total=count, unit='ids')\n",
    "        add_ids = [id_.text for id_ in tree.findall('IdList/Id')]\n",
    "        ids += add_ids\n",
    "        payload['retstart'] += retmax\n",
    "        progress_bar.update(len(add_ids))\n",
    "        time.sleep(sleep)\n",
    "    progress_bar.close()\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run esearch queries\n",
    "payload = {\n",
    "    'db': 'pubmed',\n",
    "    'term': f'journal article[Publication Type] AND {start_year}:{end_year}[Date - Publication]'\n",
    "}\n",
    "pubmed_ids = esearch_query(payload)\n",
    "pubmed_ids = sorted(map(int, pubmed_ids))\n",
    "id_df = pandas.DataFrame({'pubmed_id': pubmed_ids})\n",
    "id_df.to_csv(path_ids, compression='xz', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `esummary`: retrieve article summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23,711,961 pubmed IDs'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read pubmed IDs\n",
    "pubmed_ids = list(pandas.read_table(path_ids).pubmed_id)\n",
    "f'{len(pubmed_ids):,} pubmed IDs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pubmed_esummary(ids, write_file, retmax=100, retmin=20, sleep=0.34, error_sleep=10):\n",
    "    \"\"\"Submit an ESummary query for PubMed records and write results as xml to write_file.\"\"\"\n",
    "    \n",
    "    # Base URL for PubMed's esummary eutlity\n",
    "    url = 'http://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi'\n",
    "        \n",
    "    # Set up progress stats\n",
    "    n_total = len(ids)\n",
    "    successive_errors = 0\n",
    "    progress_bar = tqdm.tqdm_notebook(total=n_total, unit='articles')\n",
    "\n",
    "    # Write first line of XML\n",
    "    write_file.write('<eSummaryResult>\\n')\n",
    "\n",
    "    # Set up queue\n",
    "    idq = collections.deque()\n",
    "    for i in range(0, len(ids), retmax):\n",
    "        idq.append(ids[i:i+retmax])\n",
    "\n",
    "    # Query until the queue is empty\n",
    "    while idq:\n",
    "        time.sleep(sleep)\n",
    "        id_subset = idq.popleft()\n",
    "        id_subset_len = len(id_subset)\n",
    "        \n",
    "        # Perform eutilities API request\n",
    "        id_string = ','.join(map(str, id_subset))\n",
    "        payload = {'db': 'pubmed', 'id': id_string, 'rettype': 'xml'}\n",
    "        try:\n",
    "            response = requests.get(url, params=payload)\n",
    "            tree = lxml.etree.fromstring(response.content)\n",
    "            successive_errors = 0\n",
    "        except Exception as e:\n",
    "            successive_errors += 1\n",
    "            logger.warning(f'{successive_errors} successive error: {id_subset_len} IDs [{id_subset[0]} â€¦ {id_subset[-1]}] threw {e}')\n",
    "            if id_subset_len >= retmin * 2:\n",
    "                mid = len(id_subset) // 2\n",
    "                idq.appendleft(id_subset[:mid])\n",
    "                idq.appendleft(id_subset[mid:])\n",
    "            else:\n",
    "                idq.appendleft(id_subset)\n",
    "            time.sleep(error_sleep * successive_errors)\n",
    "            continue\n",
    "\n",
    "        # Write XML to file\n",
    "        for docsum in tree.getchildren():\n",
    "            xml_str = lxml.etree.tostring(docsum, encoding='unicode')\n",
    "            write_file.write(xml_str)\n",
    "        \n",
    "        # Report progress\n",
    "        progress_bar.update(id_subset_len)\n",
    "    \n",
    "    progress_bar.close()\n",
    "    # Write final line of XML\n",
    "    write_file.write('</eSummaryResult>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9727500/|/ 41%|| 9727500/23711961 [5:03:24<8:05:42, 479.87articles/s]\n",
      "CPU times: user 4h 30min 53s, sys: 1min 48s, total: 4h 32min 41s\n",
      "Wall time: 13h 30min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Run esummary queries\n",
    "with lzma.open(path_summaries, 'wt') as write_file:\n",
    "    pubmed_esummary(pubmed_ids, write_file, retmax=500, retmin=50, sleep=0, error_sleep=1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:delays]",
   "language": "python",
   "name": "conda-env-delays-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "5d54a907ed7d478ba50094f6523a96f7": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "b9f9686bb8a24e7aa7244b48ec1d1937": {
     "views": [
      {
       "cell_index": 11
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
