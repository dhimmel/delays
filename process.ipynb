{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process PubMed data and export  to TSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bz2\n",
    "import datetime\n",
    "import importlib\n",
    "import mimetypes\n",
    "import os\n",
    "import re\n",
    "import xml.etree.ElementTree\n",
    "\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract historical dates from PubMed records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve PubMed records for all journal articles between 1950 and 2015\n",
    "\n",
    "Enter the following search in [PubMed](http://www.ncbi.nlm.nih.gov/pubmed/):\n",
    "\n",
    "```\n",
    "journal article[pt] AND (\"1950/01/01\"[PDAT] : \"2015/12/31\"[PDAT])\n",
    "```\n",
    "\n",
    "Then click `Send to:`, then choose `File`, then select `XML` for format and publication date for `Sort by`.\n",
    "\n",
    "After `pubmed_result.xml` finishes downloading, rename it to `pubmed_journal-articles_1950-2015.xml` and compress the file with bzip2.\n",
    "\n",
    "**Note**: This method for retrieving PubMed records has been [used](https://twitter.com/clathrin/status/688054056800092165) by Steve Royle for a [similar analysis](https://quantixed.wordpress.com/2015/03/16/waiting-to-happen-ii-publication-lag-times/). For this project, we were [previousely retrieving](https://github.com/dhimmel/delays/blob/756ffebf309499a500ec1f83d68803c044ec8729/process.ipynb) history dates from `pubmed-dates-3.txt.gz` available at `ftp://ftp.ncbi.nlm.nih.gov/pubmed/`. However, K. Majewski from the NLM said that `pubmed-dates-3.txt.gz` was created for a special research project and may not contain all records. Therefore, we adopted the Royle method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "encoding_to_module = {\n",
    "    'gzip': 'gzip',\n",
    "    'bzip2': 'bz2',\n",
    "}\n",
    "\n",
    "def iterparse(path):\n",
    "    \"\"\"Return an element tree generator.\"\"\"\n",
    "    # Automatically detect compression\n",
    "    type_, encoding = mimetypes.guess_type(path)\n",
    "    if encoding is None:\n",
    "        opener = open\n",
    "    else:\n",
    "        module = encoding_to_module[encoding]\n",
    "        opener = importlib.import_module(module).open\n",
    "    # Open file and yield from the element tree\n",
    "    with opener(path, 'rt') as read_file:\n",
    "        yield from xml.etree.ElementTree.iterparse(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_pmpd(elem):\n",
    "    \"\"\"Parse an `PubmedArticle/PubmedData/History/PubMedPubDate` element.\"\"\"\n",
    "    year = elem.findtext('Year')\n",
    "    month = elem.findtext('Month')\n",
    "    day = elem.findtext('Day')\n",
    "    date_tuple = year, month, day\n",
    "    if not all(date_tuple):\n",
    "        return None\n",
    "    year, month, day = map(int, date_tuple)\n",
    "    return datetime.date(year, month, day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join('download', 'pubmed_dhimmel.xml.bz2')\n",
    "articles = list()\n",
    "for event, elem in iterparse(path):\n",
    "    if elem.tag != 'PubmedArticle':\n",
    "        continue\n",
    "    article = dict()\n",
    "    \n",
    "    article['pubmed_id'] = int(elem.findtext('MedlineCitation/PMID'))\n",
    "    article['journal_nlm_id'] = elem.findtext('MedlineCitation/MedlineJournalInfo/NlmUniqueID')\n",
    "    \n",
    "    # Extract all historical dates\n",
    "    for pmpd in elem.findall('PubmedData/History/PubMedPubDate[@PubStatus]'):\n",
    "        key = pmpd.get('PubStatus')\n",
    "        value = parse_pmpd(pmpd)\n",
    "        if value is None:\n",
    "            continue\n",
    "        article[key] = value\n",
    "    articles.append(article)\n",
    "\n",
    "article_df = pandas.DataFrame(articles)\n",
    "article_df = article_df.sort_values(by='pubmed_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine `aheadofprint` and `epublish`\n",
    "article_df['date_online'] = article_df['aheadofprint']\n",
    "article_df['date_online'].fillna(article_df['epublish'], inplace=True)\n",
    "\n",
    "# Compute proportion missing for each column\n",
    "missing_pct = article_df.isnull().mean().sort_values()\n",
    "article_df = article_df[missing_pct.index]\n",
    "missing_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "article_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save article_df\n",
    "path = os.path.join('data', 'articles-all.tsv.bz2')\n",
    "with bz2.open(path, 'wt') as write_file:\n",
    "    article_df.to_csv(write_file, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process PubMed journal catalog\n",
    "\n",
    "Download and process PubMed/NLM [journal catalog](http://www.ncbi.nlm.nih.gov/books/NBK3827/table/pubmedhelp.T.journal_lists/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download PubMed Journals\n",
    "url = 'ftp://ftp.ncbi.nih.gov/pubmed/J_Medline.txt'\n",
    "! wget --no-verbose --directory-prefix download --timestamping {url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read PubMed journals\n",
    "path = os.path.join('download', 'J_Medline.txt')\n",
    "with open(path) as read_file:\n",
    "    text = read_file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe of PubMed journals\n",
    "rows = list()\n",
    "pattern = re.compile('^-+$', re.MULTILINE)\n",
    "for stanza in re.split(pattern, text):\n",
    "    stanza = stanza.strip()\n",
    "    if not stanza:\n",
    "        continue\n",
    "    row = dict()\n",
    "    for line in stanza.split('\\n'):\n",
    "        key, value = line.split(': ', 1)\n",
    "        row[key] = value or None\n",
    "    rows.append(row)\n",
    "\n",
    "journal_df = pandas.DataFrame(rows)\n",
    "journal_df = journal_df.sort_values(by='NlmId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Order columns by percent missing\n",
    "missing_pct = journal_df.isnull().mean().sort_values()\n",
    "journal_df = journal_df[missing_pct.index]\n",
    "missing_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save journal dataframe as a TSV\n",
    "path = 'data/pubmed-journals.tsv'\n",
    "journal_df.to_csv(path, sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
