{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process PubMed data to extract article history dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import xml.etree.ElementTree\n",
    "import gzip\n",
    "import os\n",
    "import datetime\n",
    "import calendar\n",
    "import csv\n",
    "\n",
    "import pandas\n",
    "import matplotlib\n",
    "import seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download `pubmed-dates-3.txt.gz`\n",
    "url = 'ftp://ftp.ncbi.nlm.nih.gov/pubmed/pubmed-dates-3.txt.gz'\n",
    "! wget --timestamping --no-verbose --directory-prefix download {url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the xml export. memory intensive\n",
    "path = os.path.join('download', 'pubmed-dates-3.txt.gz')\n",
    "with gzip.open(path, 'rt') as read_file:\n",
    "    element_tree = xml.etree.ElementTree.parse(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "month_abbr_to_int = {v: k for k, v in enumerate(calendar.month_abbr)}\n",
    "del month_abbr_to_int['']\n",
    "\n",
    "def parse_pmpd(elem):\n",
    "    \"\"\"Parse an `ArticleDates/History/PubMedPubDate` element.\"\"\"\n",
    "    \n",
    "    # parse year and day\n",
    "    try:\n",
    "        year = int(elem.findtext('Year'))\n",
    "        day = int(elem.findtext('Day'))\n",
    "    except ValueError:\n",
    "        return None\n",
    "    \n",
    "    # parse month\n",
    "    month = elem.findtext('Month')\n",
    "    try:\n",
    "        month = int(month)\n",
    "    except ValueError:\n",
    "        month = month_abbr_to_int.get(month)\n",
    "    \n",
    "    return date_no_exceptions(year, month, day)\n",
    "\n",
    "def date_no_exceptions(year, month, day):\n",
    "    \"\"\"Return a datetime.date or `None` in case of error.\"\"\"\n",
    "    try:\n",
    "        return datetime.date(year, month, day)\n",
    "    except TypeError:\n",
    "        return None\n",
    "    except ValueError:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Parse and process xml\n",
    "articles = list()\n",
    "for elem in element_tree.iterfind('ArticleDates'):\n",
    "    article = dict()\n",
    "    \n",
    "    article['pubmed_id'] = int(elem.findtext('PMID'))\n",
    "    article['journal'] = elem.findtext('MedlineJournalInfo/MedlineTA')\n",
    "    article['journal_issn'] = elem.findtext('MedlineJournalInfo/ISSNLinking')\n",
    "    article['journal_nlm_id'] = elem.findtext('MedlineJournalInfo/NlmUniqueID')\n",
    "    \n",
    "    for pmpd in elem.findall('History/PubMedPubDate[@PubStatus]'):\n",
    "        key = pmpd.get('PubStatus')\n",
    "        value = parse_pmpd(pmpd)\n",
    "        if value is None:\n",
    "            break\n",
    "        article[key] = value\n",
    "    articles.append(article)\n",
    "\n",
    "article_df = pandas.DataFrame(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine `aheadofprint` and `epublish`\n",
    "article_df['date_online'] = article_df['aheadofprint']\n",
    "article_df['date_online'].fillna(article_df['epublish'], inplace=True)\n",
    "\n",
    "# Compute proportion missing for each column\n",
    "missing_pct = article_df.isnull().mean().sort_values()\n",
    "article_df = article_df[missing_pct.index]\n",
    "missing_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select a subset of columns\n",
    "columns = ['journal', 'journal_issn', 'pubmed_id', 'received', 'revised', 'accepted', 'date_online']\n",
    "filtered_df = article_df[columns]\n",
    "print('{} articles before filtering'.format(len(filtered_df)))\n",
    "\n",
    "# Filter articles by missing values\n",
    "columns.remove('revised')\n",
    "filtered_df = filtered_df.dropna(subset=columns)\n",
    "print('{} articles after removing missing dates'.format(len(filtered_df)))\n",
    "\n",
    "# calculate delays in days\n",
    "filtered_df['acceptance_delay'] = (filtered_df.accepted - filtered_df.received).dt.days\n",
    "filtered_df['publication_delay'] = (filtered_df.date_online - filtered_df.accepted).dt.days\n",
    "\n",
    "# Remove anachronistic articles\n",
    "filtered_df = filtered_df.query('(acceptance_delay >= 0) & (publication_delay >= 0)')\n",
    "filtered_df = filtered_df[filtered_df.received >= datetime.date(2000, 1, 1)]\n",
    "filtered_df = filtered_df[filtered_df.date_online <= datetime.date.today()]\n",
    "print('{} articles after removing anachronistic dates'.format(len(filtered_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Oudated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_dates(path):\n",
    "    \"\"\"\n",
    "    Parse `pubmed-dates.txt` or `pubmed-dates-2.txt`.\n",
    "    \"\"\"\n",
    "    read_file = open(path)\n",
    "    reader = csv.reader(read_file, delimiter='\\t')\n",
    "    articles = list()\n",
    "    for row in reader:\n",
    "        article = collections.OrderedDict()\n",
    "        article['pubmed_id'] = row[0]\n",
    "        article['journal'] = row[1]\n",
    "        for field in row[2:]:\n",
    "            key, value = field.split(':')\n",
    "            article[key] = value\n",
    "        articles.append(article)\n",
    "    read_file.close()\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = '/home/dhimmels/Desktop/pubmed-dates.txt'\n",
    "articles_1 = read_dates(path)\n",
    "\n",
    "path = '/home/dhimmels/Desktop/pubmed-dates-2.txt'\n",
    "articles_2 = read_dates(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a1_df = pandas.DataFrame(articles_1)\n",
    "a2_df = pandas.DataFrame(articles_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(a1_df), len(a2_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum(a1_df.pubmed_id.isin(a2_df.pubmed_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a1_df.sort_values('pubmed_id').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a2_df.sort_values('pubmed_id').tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
